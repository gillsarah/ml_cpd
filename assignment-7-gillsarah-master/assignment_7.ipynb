{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from bokeh.plotting import figure, show \n",
    "from bokeh.layouts import gridplot\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "from bokeh.models.widgets import Panel, Tabs\n",
    "from bokeh.models import HoverTool\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sarah/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (4,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#this is the path to the chicago-police-data GitHub, \n",
    "#used to access unified_data.zip and discipline_penalty_codes.csv\n",
    "#data_path = '/Users/Sarah/Documents/GitHub/chicago-police-data/data'\n",
    "\n",
    "#Code has been changed so that you can access all of the data from one location\n",
    "#instences of data_path have been changed to path\n",
    "#all of the needed data is in my HW5 Repository\n",
    "\n",
    "\n",
    "\n",
    "#this is the save-to path, this is where the unified_data.zip unzips to\n",
    "#and where we read the accused, investigators and victims data from (out of the unzipped contents)\n",
    "#path =  '/Users/Sarah/Documents/GitHub/assignment-4-gillsarah'\n",
    "path= '/Users/Sarah/Documents/GitHub/assignment-5-sarah-gill-1'\n",
    "\n",
    "#profile_path = 'unified_data/profiles/officer-profiles.csv.gz' #path for reading from chicago-police-data\n",
    "profile_path = 'fully-unified-data/profiles/officer-profiles.csv.gz'\n",
    "codes_path = 'context_data/discipline_penalty_codes.csv'\n",
    "base_path = 'fully-unified-data/complaints/complaints-{}_2000-2016_2016-11.csv.gz'\n",
    "file_name = ['accused', 'investigators', 'victims']\n",
    "\n",
    "\n",
    "def pathmaker(base_path, file):\n",
    "    return base_path.format(file)\n",
    "\n",
    "\n",
    "def unzip(path, filename, save_to_path):\n",
    "    zf = ZipFile(os.path.join(path, filename), 'r')\n",
    "    zf.extractall(save_to_path)\n",
    "    zf.close()\n",
    "    #cite: https://stackoverflow.com/questions/3451111/unzipping-files-in-python\n",
    "\n",
    "\n",
    "def read_df(path, filename):\n",
    "    df = pd.read_csv(os.path.join(path, filename))\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_accused(accused_df):\n",
    "    accused_df.drop(columns = 'row_id', inplace = True)\n",
    "    final_dummies = pd.get_dummies(accused_df['final_finding'])\n",
    "    #recommend_dummies = pd.get_dummies(accused_df['recommended_finding'])\n",
    "    #cite https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html\n",
    "    accused_df['sustained'] = final_dummies['SU']\n",
    "    #accused_df['recommend_sustain'] = recommend_dummies['SU']\n",
    "    return accused_df\n",
    "\n",
    "\n",
    "def parse_investigarots(investigators_df):\n",
    "    investigators_df.drop(columns = 'row_id', inplace = True)\n",
    "    investigators_df.rename(columns = {'first_name':'investigator_first_name', \n",
    "                                       'last_name':'investigator_last_name',\n",
    "                                       'middle_initial':'investigator_middle_initial', \n",
    "                                       'suffix_name':'investigator_suffix',\n",
    "                                       'appointed_date': 'date_investigator_appointed', \n",
    "                                       'current_star':'investigator_current_star_number',\n",
    "                                       'current_rank': 'investigator_current_rank', \n",
    "                                       'current_unit':'investigator_current_unit'}, inplace = True)\n",
    "    return investigators_df\n",
    "\n",
    "def parse_victims(victims_df):\n",
    "    victims_df.rename(columns = {'gender':'victim_gender', 'age':'victim_age', \n",
    "                                 'race':'victim_race'}, inplace = True)\n",
    "    return victims_df\n",
    "\n",
    "def parse_profile(profile_df):\n",
    "    profile_df['org_hire_date'] = pd.to_datetime(profile_df['org_hire_date'], \n",
    "                                                 format='%Y-%m-%d')\n",
    "    #profile_df['birth_year'] = pd.to_datetime(profile_df['birth_year'], format='%Y')\n",
    "    profile_df['Year_hired'] = profile_df['org_hire_date'].map(lambda d: d.year)\n",
    "    return profile_df\n",
    "\n",
    "def merge_dfs(dfs):\n",
    "    '''\n",
    "    takes a list of dfs, the order is decided in the list dfs. If you change the order, the function\n",
    "    may need to be tweeked. The suffixes, and merges 3 and 4\n",
    "    The frist df is accused, the second is investigators, the third is victims, the third is codes\n",
    "    '''\n",
    "    merge_0 = dfs[0].merge(dfs[4], how = 'left', on = 'UID', suffixes = ('_accused', '_profile'))\n",
    "    merge_1 = merge_0.merge(dfs[1], how = 'inner', on =  \"cr_id\", suffixes = ('_accused','_investigators'))\n",
    "    merge_2 = merge_1.merge(dfs[2], how = 'inner', on =  \"cr_id\")\n",
    "    merge_3 = merge_2.merge(dfs[3], how = 'left', left_on = 'recommended_discipline', right_on = 'CODE')\n",
    "\n",
    "    merge_3.drop(columns = 'CODE', inplace = True)\n",
    "    merge_3.rename(columns={'recommended_discipline': 'recommended_discipline_code',\n",
    "                            'ACTION_TAKEN'          : 'recommended_discipline'      }, inplace = True)       \n",
    "    \n",
    "    merge_4 = merge_3.merge(dfs[3], how = 'left', left_on = 'final_discipline', \n",
    "                            right_on = 'CODE',suffixes = ('_recommended_discipline', '_final_discipline'))\n",
    "\n",
    "    merge_4.drop(columns = 'CODE', inplace = True)\n",
    "\n",
    "    merge_4.rename(columns={'final_discipline': 'final_discipline_code',\n",
    "                            'ACTION_TAKEN'    : 'final_discipline'     }, inplace = True) \n",
    "    merge_4['count'] = 1 \n",
    "    return merge_4\n",
    "\n",
    "\n",
    "#proportion sustained: looking at all complaints filed, one entry per accused individual\n",
    "def total_proportion(accused_df):\n",
    "    return accused_df['sustained'].sum()/len(accused_df.index)\n",
    "\n",
    "#proportion sustained of complaints that have a line in victims, investigarots and accused \n",
    "def outcome_by_race(df, outcome_word):\n",
    "    grouped = df.groupby('victim_race').sum()\n",
    "    grouped[outcome_word]\n",
    "    grouped['proportion_'+outcome_word] = grouped[outcome_word]/len(df.index)\n",
    "    df = grouped['proportion_'+outcome_word]\n",
    "\n",
    "    #print('The proportion of complaints '+outcome_word+', by race of the victim:')\n",
    "    #print(grouped['proportion_'+outcome_word])\n",
    "    return df\n",
    "\n",
    "\n",
    "def complaint_type_outcomes(accused_df, outcome, outcome_word):\n",
    "    '''\n",
    "    takes the acccused df, the two letter string for final finding: e.g. 'SU' and a string \n",
    "    for the final finding abbreviation meaning (e.g. 'sustained' for 'SU')\n",
    "    output is a list of the complaint catagories for which the outcome (e.g. 'SU')\n",
    "    is the most likely final finding\n",
    "    '''\n",
    "    crosstab = pd.crosstab(accused_df['final_finding'], accused_df['complaint_category'])\n",
    "    #cite https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html\n",
    "\n",
    "    #print('The following complaint catagories are most likely to be ' + outcome_word + ':')\n",
    "    temp_list = []\n",
    "    for column in crosstab.columns:\n",
    "        if crosstab[column].idxmax() == outcome:\n",
    "            print(column)\n",
    "            temp_list.append(column)\n",
    "    #cite: https://stackoverflow.com/questions/15741759/find-maximum-value-of-a-column-and-return-the-corresponding-row-values-using-pan\n",
    "    df = pd.DataFrame(temp_list, columns = ['complaint catagories most likely to be ' + outcome_word]) \n",
    "    #cite: https://www.geeksforgeeks.org/create-a-pandas-dataframe-from-lists/\n",
    "    return df\n",
    "\n",
    "def export_df(df, path, filename):\n",
    "    df.to_csv(os.path.join(path, filename))\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    files = []\n",
    "    for f in file_name:\n",
    "        files.append(pathmaker(base_path, f))\n",
    "\n",
    "    #commented out for useing only one data path\n",
    "    #unzip(data_path, 'unified_data/unified_data.zip', path)\n",
    "\n",
    "    dfs = []\n",
    "    for filename in files:\n",
    "        df = read_df(path, filename)\n",
    "        if filename.__contains__('accused'):\n",
    "            dfs.append(parse_accused(df))\n",
    "        elif filename.__contains__('investigators'):\n",
    "            dfs.append(parse_investigarots(df))\n",
    "        elif filename.__contains__('victims'):\n",
    "            dfs.append(parse_victims(df))\n",
    "        else:\n",
    "            print('unexpected file')\n",
    "    dfs.append(read_df(path, codes_path))\n",
    "    \n",
    "    df2 = read_df(path, profile_path)\n",
    "    dfs.append(parse_profile(df2))\n",
    "\n",
    "    df = merge_dfs(dfs)\n",
    "\n",
    "    #proportion = total_proportion(dfs[0])\n",
    "    #print('Total proportion of complaints that are sustained: {:.4f}'.format(proportion))\n",
    "    #print(' ')\n",
    "\n",
    "    #race_df = outcome_by_race(df, 'sustained')\n",
    "\n",
    "\n",
    "    #outcome_df = complaint_type_outcomes(dfs[0], 'SU', 'sustained')\n",
    "\n",
    "    export_df(df, path, 'full_df.csv')\n",
    "    #export_df(race_df, path, 'Proportion of compliants sustained by race.csv')\n",
    "    #export_df(outcome_df, path, 'Most likely to be sustained.csv')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, col1, col2='gender', value1 = 'all', value2= 'all'):\n",
    "    if value1 == 'all':\n",
    "        filtered_df = df\n",
    "    else:\n",
    "        filtered_df = df[df[col1] == value1]\n",
    "    \n",
    "    if value2 == 'all':\n",
    "        filtered_df2 = filtered_df\n",
    "    else:\n",
    "        filtered_df2 = filtered_df[filtered_df[col2]== value2]\n",
    "    return filtered_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_df_maker(df, col1, col2, col3 = 'count'):\n",
    "    '''\n",
    "    takes a df and two strings: 3 column names in that df, that you want to work with\n",
    "    returns a dictionary ready to be used in to my_fn\n",
    "    '''\n",
    "    \n",
    "    drop_list = []\n",
    "    for colname in df.columns:\n",
    "        if colname in [col1, col2, col3]:\n",
    "            pass\n",
    "        else:\n",
    "            drop_list.append(colname)\n",
    "    df2 = df.drop(columns = drop_list)\n",
    "    df3 = dict(tuple(df2.groupby(col1)))\n",
    "    #cite https://stackoverflow.com/questions/19790790/splitting-dataframe-into-multiple-dataframes\n",
    "    return df3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fn(df, officer_string, col1, col2, col3 = 'count', title = \" \"):\n",
    "    '''\n",
    "    takes a string value for officer, what you want to groubby\n",
    "    e.g. 'WHITE' or 'MALE'\n",
    "    this needs to line up with the values for col1 (e.g. 'race' or 'gender')\n",
    "    takes a string value for the colum name \n",
    "    e.g. 'victim_race' or 'victim_gender'\n",
    "    output is a bar graph of col2 grouped by col1\n",
    "    '''\n",
    "    df2 = small_df_maker(df, col1, col2, col3 = 'count')\n",
    "    g = df2[officer_string].groupby(col2, as_index = False).sum()\n",
    "    #g.reset_index(inplace=True)\n",
    "    \n",
    "    hover = HoverTool(tooltips = [('count', '@top')])\n",
    "    #cite https://towardsdatascience.com/data-visualization-with-bokeh-in-python-part-one-getting-started-a11655a467d4\n",
    "       \n",
    "    plot = figure(x_range= g[col2], plot_height=450, plot_width = 1500, title=title,\n",
    "           toolbar_location=None, tools=[hover])\n",
    "\n",
    "    plot.xaxis.major_label_orientation = pi/4\n",
    "    #cite https://stackoverflow.com/questions/42354648/how-to-rotate-x-axis-labels-in-bokeh-figure\n",
    "    #cite https://docs.bokeh.org/en/latest/docs/user_guide/styling.html#tick-label-orientation\n",
    "    plot.vbar(g[col2], top = g[col3], width = 0.8)\n",
    "    #cite https://docs.bokeh.org/en/latest/docs/user_guide/categorical.html\n",
    "    \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "officer_race = df.reset_index()['race'].unique()\n",
    "#officer_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(race_of_officer=officer_race) #dropdown menue\n",
    "def make_plot_for(race_of_officer= officer_race[0]):\n",
    "    tabs = tab(df, race_of_officer, 'race', 'victim_race', 'final_finding', 'cleaned_rank',\n",
    "               'Victim Race', 'Complaint Finding', 'Officer Rank') \n",
    "    show(tabs) #show the plot\n",
    "\n",
    "    #rate: complaints against this type of officer: % by this grouping \n",
    "    #can make the x-axis on an angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['complaint_category'].fillna('not listed', inplace = True)\n",
    "#cite: https://stackoverflow.com/questions/13295735/how-can-i-replace-all-the-nan-values-with-zeros-in-a-column-of-a-pandas-datafra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaint_cat = df.reset_index()['complaint_category'].unique()\n",
    "#complaint_cat\n",
    "race = df.reset_index()['race'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adce41a92dfb4549b91e44dc81687c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='race', options=('WHITE', 'HISPANIC', 'BLACK', 'ASIAN/PACIFIC ISLAN…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@interact_manual(type_of_complaint=complaint_cat, sustained_only=False) #dropdown menue\n",
    "@interact_manual(race=race, sustained_only=False)\n",
    "#def make_plot_for(type_of_complaint= complaint_cat[0], sustained_only=False):\n",
    "def make_plot_for(race = race[0], sustained_only=False):\n",
    "    if sustained_only:\n",
    "        #df_new = filter_df(df, 'race', value1='SU')\n",
    "        df_new = filter_df(df, 'complaint_category', value1='SU')\n",
    "        \n",
    "    else:\n",
    "        df_new = df\n",
    "     #type_of_complaint   \n",
    "    plot = my_fn(df_new, race , col2= 'complaint_category', col1 = 'race', \n",
    "                 title = \"Final Discipline by Type of Complaint\" )\n",
    "    show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
